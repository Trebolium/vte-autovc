{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, pdb, pickle, argparse, shutil, yaml, torch, math, time, pdb, datetime, pickle\n",
    "import utils #file\n",
    "from solver_encoder import Solver \n",
    "from data_loader import pathSpecDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.backends import cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "import torch.nn.functional as F\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(adam_init=0.0001, autovc_ckpt='/homes/bdoc3/my_data/autovc_data/vte-autovc/model_saves/vteautovcWithAvgVtesNoCdLoss/ckpts/ckpt_500000.pth.tar', batch_size=1, chunk_num=6, chunk_seconds=0.5, ckpt_freq=10000, config_file='', data_dir='/homes/bdoc3/my_data/autovc_data/vte-autovc', device=device(type='cuda', index=0), dim_emb=256, dim_neck=32, dim_pre=512, emb_ckpt='/homes/bdoc3/phonDet/results/newStandardAutovcSpmelParamsUnnormLatent64Out256/best_epoch_checkpoint.pth.tar', file_name='vteautovcWithAvgVtesNoCdLoss', freq=16, lambda_cd=1, len_crop=192, log_step=10, num_iters=500000, one_hot=False, prnt_loss_weight=1.0, psnt_loss_weight=1.0, shape_adapt=True, spec_freq=10000, spmel_dir='/homes/bdoc3/my_data/phonDet/spmel_autovc_params_unnormalized', train_size=21, vte_ckpt='/homes/bdoc3/phonDet/results/newStandardAutovcSpmelParamsUnnormLatent64Out256/best_epoch_checkpoint.pth.tar', which_cuda=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tailor config, define other \n",
    "model_name = 'vteautovcWithAvgVtesNoCdLoss'\n",
    "cudnn.benchmark = True\n",
    "use_avg_vte = True\n",
    "convert_style = True\n",
    "autovc_model_saves_dir = '/homes/bdoc3/my_data/autovc_data/vte-autovc/model_saves/'\n",
    "autovc_model_dir = autovc_model_saves_dir + model_name\n",
    "config = pickle.load(open(autovc_model_dir +'/config.pkl','rb'))\n",
    "ckpt_iters = 500000\n",
    "config.which_cuda = 0\n",
    "config.batch_size = 1\n",
    "config.autovc_ckpt = autovc_model_dir +'/ckpts/ckpt_' +str(ckpt_iters) +'.pth.tar'\n",
    "avg_embs = np.load(os.path.dirname(config.emb_ckpt) +'/averaged_embs.npy')\n",
    "config.vte_ckpt = '/homes/bdoc3/phonDet/results/newStandardAutovcSpmelParamsUnnormLatent64Out256/best_epoch_checkpoint.pth.tar'\n",
    "# additional config attrs\n",
    "style_names = ['belt','lip_trill','straight','vocal_fry','vibrato','breathy']\n",
    "singer_names = ['m1_','m2_','m3_','m4_','m5_','m6_','m7_','m8_','m9_','m10_','m11_','f1_','f2_','f3_','f4_','f5_','f6_','f7_','f8_','f9_']\n",
    "male_idx = range(0,11)\n",
    "female_idx = range(11,20)\n",
    "config.device = torch.device(f'cuda:{config.which_cuda}' if torch.cuda.is_available() else 'cpu')\n",
    "with open(config.spmel_dir +'/spmel_params.yaml') as File:\n",
    "    spmel_params = yaml.load(File, Loader=yaml.FullLoader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/homes/bdoc3/vte-autovc', '/homes/bdoc3/my_data/autovc_data/vte-autovc/model_saves/vteautovcWithAvgVtesNoCdLoss', '/homes/bdoc3/my_data/autovc_data/vte-autovc/model_saves/vteautovcWithAvgVtesNoCdLoss', '/homes/bdoc3/my_data/autovc_data/vte-autovc/model_saves/vteautovcWithAvgVtesNoCdLoss', '', '/import/linux/python/3.7.7/lib/python3.7/site-packages', '/import/linux/python/3.7.7/lib/python37.zip', '/import/linux/python/3.7.7/lib/python3.7', '/import/linux/python/3.7.7/lib/python3.7/lib-dynload', '/homes/bdoc3/.local/lib/python3.7/site-packages', '/homes/bdoc3/.local/lib/python3.7/site-packages/IPython/extensions', '/homes/bdoc3/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# import path to use autovc_model_dir's .py\n",
    "import sys\n",
    "sys.path.insert(1, autovc_model_dir) # usually the cwd is priority, so index 1 is good enough for our purposes here\n",
    "print(sys.path)\n",
    "from this_model_vc import Generator\n",
    "\n",
    "config.batch_size=1\n",
    "# setup dataloader, models\n",
    "vocalSet = pathSpecDataset(config, spmel_params)\n",
    "vocalSet_loader = DataLoader(vocalSet, batch_size=config.batch_size, shuffle=True, drop_last=False)\n",
    "G = utils.setup_gen(config, Generator)\n",
    "vte = utils.setup_vte(config, spmel_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir_for_wavs = autovc_model_dir +'/generated_wavs/' +str(ckpt_iters) +'iters'\n",
    "if os.path.exists(subdir_for_wavs)==False:\n",
    "        os.makedirs(subdir_for_wavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/homes/bdoc3/vte-autovc', '/homes/bdoc3/my_data/autovc_data', '/homes/bdoc3/my_data/autovc_data', '/homes/bdoc3/my_data/autovc_data', '/homes/bdoc3/my_data/autovc_data', '/homes/bdoc3/my_data/autovc_data', '/homes/bdoc3/my_data/autovc_data', '/homes/bdoc3/my_data/autovc_data', '/homes/bdoc3/my_data/autovc_data', '/homes/bdoc3/my_data/autovc_data', '/homes/bdoc3/my_data/autovc_data', '/homes/bdoc3/my_data/autovc_data/vte-autovc/model_saves/vteautovcWithAvgVtesNoCdLoss', '/homes/bdoc3/my_data/autovc_data/vte-autovc/model_saves/vteautovcWithAvgVtesNoCdLoss', '/homes/bdoc3/my_data/autovc_data/vte-autovc/model_saves/vteautovcWithAvgVtesNoCdLoss', '', '/import/linux/python/3.7.7/lib/python3.7/site-packages', '/import/linux/python/3.7.7/lib/python37.zip', '/import/linux/python/3.7.7/lib/python3.7', '/import/linux/python/3.7.7/lib/python3.7/lib-dynload', '/homes/bdoc3/.local/lib/python3.7/site-packages', '/homes/bdoc3/.local/lib/python3.7/site-packages/IPython/extensions', '/homes/bdoc3/.ipython']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 21899/49152 [05:00<06:14, 72.79it/s]"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/homes/bdoc3/my_data/autovc_data') # usually the cwd is priority, so index 1 is good enough for our purposes here\n",
    "print(sys.path)\n",
    "from hparams import hparams\n",
    "# importlib.reload(synthesis)\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pickle\n",
    "from synthesis import build_model\n",
    "from synthesis import wavegen\n",
    "\n",
    "model = build_model().to(config.device)\n",
    "checkpoint = torch.load(\"/homes/bdoc3/my_data/autovc_data/checkpoint_step001000000_ema.pth\")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "find_male = True\n",
    "num_examples = 8\n",
    "counter = 0\n",
    "while counter < num_examples:\n",
    "    data_iter = iter(vocalSet_loader)\n",
    "    x_real, org_style_idx, singer_idx = next(data_iter)\n",
    "    x_real = x_real.to(config.device)\n",
    "    original_spmel = x_real[0].cpu().detach().numpy()\n",
    "    if find_male == True:\n",
    "        gender_idx = male_idx\n",
    "    else:\n",
    "        gender_idx = female_idx\n",
    "    if singer_idx in gender_idx:\n",
    "        find_male = not find_male\n",
    "        counter += 1\n",
    "        if use_avg_vte == True:\n",
    "            emb_org = torch.tensor(avg_embs[org_style_idx]).to(config.device).unsqueeze(0)\n",
    "        else:\n",
    "            x_real_chunked = x_real.view(x_real.shape[0]*config.chunk_num, x_real.shape[1]//config.chunk_num, -1)\n",
    "            pred_style_idx, all_tensors = vte(x_real_chunked)\n",
    "            emb_org = all_tensors[-1]\n",
    "\n",
    "        saved_enc_outs = None\n",
    "        saved_dec_outs = None\n",
    "        all_spmels = [original_spmel]\n",
    "\n",
    "        if convert_style == False:\n",
    "            _, x_identic_psnt, _, saved_enc_outs, saved_dec_outs = G(x_real, emb_org, emb_org)\n",
    "            all_spmels.append(x_identic_psnt)\n",
    "        else:\n",
    "            for trg_style_idx in range(len(avg_embs)):\n",
    "                emb_trg = torch.tensor(avg_embs[trg_style_idx]).to(config.device).unsqueeze(0)\n",
    "                _, x_identic_psnt, _, _, _ = G(x_real, emb_org, emb_trg)\n",
    "                all_spmels.append(x_identic_psnt.squeeze(1)[0].cpu().detach().numpy())\n",
    "\n",
    "        plt.figure(figsize=(20,5))\n",
    "        for j in range(len(all_spmels)):\n",
    "            plt.subplot(1,len(all_spmels),j+1)\n",
    "            if j == 0: plt.title('original_' +str(singer_idx))    \n",
    "            else: plt.title(str(style_names[j-1] +'_' +str(singer_idx)))\n",
    "            plt.imshow(np.rot90(all_spmels[j]))\n",
    "        plt.savefig(subdir_for_wavs +'/example' +str(counter) +'_spmels')\n",
    "\n",
    "        for k, spmel  in enumerate(all_spmels):\n",
    "            # x_identic_psnt = tensor.squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "            waveform = wavegen(model, c=spmel)   \n",
    "            #     librosa.output.write_wav(name+'.wav', waveform, sr=16000)\n",
    "            if k == 0:\n",
    "                sf.write(subdir_for_wavs +'/example' +str(counter) +'_original.wav', waveform, samplerate=16000)\n",
    "            else:\n",
    "                sf.write(subdir_for_wavs +'/example' +str(counter) + '_' +style_names[k-1] +'.wav', waveform, samplerate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvautovc",
   "language": "python",
   "name": "venvautovc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
